<!DOCTYPE HTML>
<html lang="en" xmlns="http://www.w3.org/1999/html">

<head>
  <title>{{ site.name }}</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="{{ site.name }}" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="{{ site.baseurl }}/style.css" />
  <link rel="canonical" href="{{ page.url | replace:'index.html','' | prepend: site.baseurl | prepend: site.url }}">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

</head>



<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                  <name> {{ site.name }} </name>
              </h1>
              <p align="center">
                  <email> yanshen6 at msu dot edu </email>
              </p>

              <p>
              My name is Shen Yan (严珅). I am a final year PhD at the <a href="https://cse.msu.edu/">Computer Science Department</a> at <a href="https://msu.edu/">Michigan State Univiersity</a>, where I work on representation learning, AutoML and their applications. I am advised by <a href="https://www.egr.msu.edu/~mizhang/">Mi Zhang</a>.
              </p>
              <p>
                I got my M.S. in Computer Engineering from <a href="https://www.rwth-aachen.de/">RWTH Aachen University</a>, where I worked with  <a href="https://scholar.google.de/citations?user=6C8rf-0AAAAJ&hl=de">Hermann Ney</a> on face recognition and <a href="https://scholar.google.com/citations?user=NCdYnCAAAAAJ&hl=en">Jens-Rainer Ohm</a> on image retrieval. I have a B.S. in Telecommunications engineering from <a href="https://en.xidian.edu.cn/">Xidian University</a>.
              </p>
              <p style="text-align:center">
              <a href="{{ site.user.github | prepend: 'https://github.com/' }}">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=-shYRd8AAAAJ&hl=en">Google Scholar</a> /
                <a href="https://twitter.com/shawnyyan">Twitter</a> /
              <a href="{{ site.user.linkedin | prepend: 'https://www.linkedin.com/in/' }}">LinkedIn</a> /
                <a href="data/shenyan_resume.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
                <img style="width:100%;max-width:100%" alt="profile photo" src="{{ site.user.photo }}">
            </td>
          </tr>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <h2>Research</h2>
                <p>
                  <!---My general interests lie in machine learning and computer vision. Currently, I focus on representation learning and architecture search. This fits well with a nascent and fast-evolving research field referred to as neural architecture search. Representative papers are <span class="highlight">highlighted</span>. --->
                  My general interests lie in machine learning and computer vision. Currently, I focus on representation learning and architecture search, mostly in the context of visual recognition. Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"></tbody>

            <tr bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/mtv_img.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2201.04288">
                  <papertitle>Multiview Transformers for Video Recognition</papertitle>
                </a>
                <br>
                <strong>Shen Yan</strong>,
                <a href="https://scholar.google.com/citations?user=vM1SktEAAAAJ&hl=en">Xuehan Xiong</a>,
                <a href="https://scholar.google.co.uk/citations?user=l2FS2_IAAAAJ&hl=en">Anurag Arnab</a>,
                <a href="https://scholar.google.com/citations?user=pZJV-Z0AAAAJ&hl=en">Zhichao Lu</a>,
                <a href="https://scholar.google.com/citations?user=r3A90uAAAAAJ&hl=en">Mi Zhang</a>,
                <a href="https://scholar.google.com/citations?user=vQa7heEAAAAJ&hl=en">Chen Sun</a>,
                <a href="https://scholar.google.com/citations?user=IvqCXP4AAAAJ&hl=en">Cordelia Schmid</a>
                <br>
                <em>CVPR</em>, 2022 &nbsp
                <br>
                <a href="https://arxiv.org/abs/2201.04288">arXiv</a> /
                <a href="https://paperswithcode.com/paper/multiview-transformers-for-video-recognition">leaderboard</a> /
                <a href="data/yan2022mtv.bib">bibtex</a>
                <p></p>
                <p>A simple method for capturing multiresolution temporal context in transformer architectures. State-of-the-art results on five popular video datasets.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/deepaa.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openreview.net/forum?id=St-53J9ZARf">
                  <papertitle>Deep AutoAugment</papertitle>
                </a>
                <br>
                <a href="https://scholar.google.com/citations?user=6GyET_8AAAAJ&hl=en">Yu Zheng</a>,
                <strong>Shen Yan</strong>,
                <a href="https://scholar.google.com/citations?user=nZr0oXQAAAAJ&hl=en">Zhi Zhang</a>,
                <a href="https://scholar.google.com/citations?user=r3A90uAAAAAJ&hl=en">Mi Zhang</a>
                <br>
                <em>ICLR</em>, 2022 &nbsp
                <br>
                <a href="https://openreview.net/pdf?id=St-53J9ZARf">paper</a> /
                <a href="https://github.com/MSU-MLSys-Lab/DeepAA">code</a> /
                <a href="data/zheng2022deep.bib">bibtex</a>
                <p></p>
                <p>We propose to build data augmentation policies from the ground up based on regularized gradient matching.</p>
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/x11_surrogate.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2111.03602">
                <papertitle>NAS-Bench-x11 and the Power of Learning Curves</papertitle>
              </a>
              <br>
              <strong>Shen Yan</strong>*,
              <a href="https://scholar.google.com/citations?user=LS6HY-gAAAAJ&hl=en">Colin White*</a>,
              <a href="https://scholar.google.com/citations?user=WtCWzFwAAAAJ&hl=en">Yash Savani</a>,
              <a href="https://scholar.google.com/citations?user=YUrxwrkAAAAJ&hl=en">Frank Hutter</a>
              <br>
              <em>NeurIPS</em>, 2021 &nbsp
              <br>
              <a href="https://arxiv.org/abs/2111.03602">arXiv</a> /
              <a href="https://github.com/automl/nas-bench-x11">code</a> /
              <a href="data/yan2021x11.bib">bibtex</a> /
              <a href="data/nbx11_slides.pdf">slides</a>
              <p></p>
              <p>A method to create multi-fidelity NAS benchmarks and demonstrate the power of using learning curve extrapolation.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/cate.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2102.07108">
                <papertitle>CATE: Computation-aware Neural Architecture Encoding with Transformers</papertitle>
              </a>
              <br>
              <strong>Shen Yan</strong>,
              <a href="https://scholar.google.com/citations?user=PHoJwakAAAAJ&hl=en">Kaiqiang Song</a>,
              <a href="https://scholar.google.com/citations?user=22ohn6AAAAAJ&hl=en">Fei Liu</a>,
              <a href="https://scholar.google.com/citations?user=r3A90uAAAAAJ&hl=en">Mi Zhang</a>
              <br>
              <em>ICML</em>, 2021 <font color="red"><strong>(Long Presentation)</strong></font>
              <br>
              video: <a href="https://crossminds.ai/video/cate-computation-aware-neural-architecture-encoding-with-transformers-614bc93a3c7a224a9090282f/">17 min</a>/
              <a href="https://arxiv.org/abs/2102.07108">arXiv</a> /
              <a href="https://github.com/MSU-MLSys-Lab/CATE">code</a> /
              <a href="data/yan2021cate.bib">bibtex</a> /
              <a href="data/yan2021_cate_poster.pdf">poster</a>
              <p></p>
              <p>Learning the many-to-one mapping from modeling the computation relationship between architectures helps to build a flatter performance landscape.</p>
            </td>
          </tr>

          <tr onmouseout="ff_stop()" onmouseover="ff_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/unsup.png' width="160"></div>
                <img src='images/sup.png' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2006.06936">
                <papertitle>Does Unsupervised Architecture Representation Learning Help Neural Architecture Search?</papertitle>
              </a>
              <br>
              <strong>Shen Yan</strong>,
              <a href="https://scholar.google.com/citations?user=6GyET_8AAAAJ&hl=en">Yu Zheng</a>,
              <a href="https://wei-ao.github.io/">Wei Ao</a>,
              <a href="https://scholar.google.com/citations?user=fgF1HTsAAAAJ&hl=en">Xiao Zeng</a>,
              <a href="https://www.egr.msu.edu/~mizhang/">Mi Zhang</a>
              <br>
              <em>NeurIPS</em>, 2020 &nbsp
              <br>
              video: <a href="https://crossminds.ai/video/does-unsupervised-architecture-representation-learning-help-neural-architecture-search-5fb82261890833803bc7e7ed/">3 min</a>/
              <a href="https://arxiv.org/abs/2006.06936">arXiv</a> /
              <a href="https://github.com/MSU-MLSys-Lab/arch2vec">code</a> /
              <a href="data/yan2020arch.bib">bibtex</a> /
              <a href="data/yan2020arch_poster.pdf">poster</a>
              <p></p>
              <p>Pre-training architecture representations without using accuracies can better preserve the local structure relationship of neural architectures in the latent space.</p>
            </td>
          </tr>


          <tr onmouseout="mutual_stop()" onmouseover="mutual_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mutual_image'>
                  <img src='images/mutual_later.png' width="160"></div>
                <img src='images/mutualnet.png' width="160">
              </div>
              <script type="text/javascript">
                function mutual_start() {
                  document.getElementById('mutual_image').style.opacity = "1";
                }

                function mutual_stop() {
                  document.getElementById('mutual_image').style.opacity = "0";
                }
                mutual_stop()
              </script>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460290.pdf">
                <papertitle>MutualNet: Adaptive ConvNet via Mutual Learning from Network Width and Resolution</papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/view/taojiannanyang/home">Taojiannan Yang</a>,
              <a href="https://scholar.google.com/citations?user=8aO4k80AAAAJ&hl=en">Sijie Zhu</a>,
              <a href="https://webpages.uncc.edu/cchen62/">Chen Chen</a>,
              <strong>Shen Yan</strong>,
              <a href="https://www.egr.msu.edu/~mizhang/">Mi Zhang</a>,
              <a href="https://scholar.google.com/citations?user=i69G8doAAAAJ&hl=en">Andrew Wills</a>
              <br>
              <em>ECCV</em>, 2020 &nbsp <font color="red"><strong>(Oral)</strong></font>
              <br>
              video: <a href="https://www.youtube.com/watch?v=RzzxhkJConk">10 min</a>/
              <a href="https://arxiv.org/abs/1909.12978">arXiv</a> /
              <a href="https://github.com/taoyang1122/MutualNet">code</a> /
              <a href="data/yang2020mutual.bib">bibtex</a>
              <p></p>
              <p>The proposed mutual learning method for input resolution and network width significantly improves the accuracy-efficiency tradeoffs over <a href="https://arxiv.org/abs/1812.08928">slimmable networks</a>.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/mixup.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2001.00677">
                <papertitle>Improve Unsupervised Domain Adaptation with Mixup Training</papertitle>
              </a>
              <br>
              <strong>Shen Yan</strong>,
              <a href="https://scholar.google.com/citations?user=9snl7bcAAAAJ&hl=en">Huan Song</a>,
              <a href="https://scholar.google.com/citations?user=GaPN-R4AAAAJ&hl=en">Nanxiang Li</a>,
              <a href="https://scholar.google.com/citations?user=X4dfV7IAAAAJ&hl=en">Lincan Zou</a>,
              <a href="https://sites.google.com/site/liurenshomepage/">Liu Ren</a>
              <br>
              <em>arXiv</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2001.00677">arXiv</a> /
              <a href="https://github.com/facebookresearch/DomainBed">code</a> /
              <a href="data/yan2020mix.bib">bibtex</a>
              <p></p>
              <p>We propose to enforce training constraints across domains using mixup formulation to directly address the adaptation performance for unlabeled target data.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/step_k.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/NeurArch/Yan_HM-NAS_Efficient_Neural_Architecture_Search_via_Hierarchical_Masking_ICCVW_2019_paper.pdf">
                <papertitle>HM-NAS: Efficient Neural Architecture Search via Hierarchical Masking</papertitle>
              </a>
              <br>
              <strong>Shen Yan</strong>,
              <a href="http://fangbiyi.com/">Biyi Fang</a>,
              <a href="https://scholar.google.com/citations?user=9SGTrhoAAAAJ&hl=en">Faen Zhang</a>,
              <a href="https://scholar.google.com/citations?user=6GyET_8AAAAJ&hl=en">Yu Zheng</a>,
              <a href="https://scholar.google.com/citations?user=fgF1HTsAAAAJ&hl=en">Xiao Zeng</a>,
              Hui Xu,
              <a href="https://www.egr.msu.edu/~mizhang/">Mi Zhang</a>
              <br>
              <em>ICCV Neural Architects Workshop</em>, 2019 &nbsp <font color="red"><strong>(Best Paper Nomination)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/1909.00122">arXiv</a> /
              <a href="data/yan2019hm.bib">bibtex</a>
              <p></p>
              <p>Highlight the importance of topology learning in differentialable NAS.</p>
            </td>
          </tr>

          <tr onmouseout="dff_stop()" onmouseover="dff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dff_image'>
                  <img src='images/dff_resize.png' width="160"></div>
                <img src='images/ce_resize.png' width="160">
              </div>
              <script type="text/javascript">
                function dff_start() {
                  document.getElementById('dff_image').style.opacity = "1";
                }

                function dff_stop() {
                  document.getElementById('dff_image').style.opacity = "0";
                }
                dff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.bmva.org/bmvc/2017/papers/paper165/paper165.pdf">
                <papertitle>Deep Fisher Faces</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=Y9zbHswAAAAJ&hl=en">Harald Hanselmann</a>,
              <strong>Shen Yan</strong>,
              <a href="https://scholar.google.de/citations?user=6C8rf-0AAAAJ&hl=de">Hermann Ney</a>
              <br>
              <em>BMVC</em>, 2017
              <br>
              <a href="data/hanselmann2017dff.bib">bibtex</a>
              <p></p>
              <p>In this work we further extend the center (intra-class) loss with an inter-class loss reminiscent of the popular early face recognition approach Fisherfaces.</p>
            </td>
          </tr>
            </tbody></table>



          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <h2>Experience</h2>
            </td>

          </tr>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20"></tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/G.png' width="120">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                Research Intern, Student Researcher, Summer 2021, Fall 2021
                <br> <a href="https://research.google/teams/perception/">Google Research</a>, Mountain View, USA
                <br> Host: <a href="https://scholar.google.com/citations?user=vM1SktEAAAAJ&hl=en">Xuehan Xiong</a>,
                <a href="https://research.google/people/106160/">Zhichao Lu</a>,
                <a href="https://scholar.google.com/citations?user=vQa7heEAAAAJ&hl=en">Chen Sun</a>,
                <a href="https://scholar.google.com/citations?user=IvqCXP4AAAAJ&hl=en">Cordelia Schmid</a>
                <p></p>
                <p>Research on giant video Transformers.</p>
              </td>
            </tr>
          </tr>

          </table>
          <table width="100%" align="center" border="0" cellpadding="20"></tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/abacus.png' width="120">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                Research Intern, Spring 2021
                <br> <a href="https://abacus.ai/">Abacus.AI</a>, San Francisco, USA
                <br> Host: <a href="https://scholar.google.com/citations?user=LS6HY-gAAAAJ&hl=en">Colin White</a>
                <p></p>
                <p>Research on multi-fidelity AutoML.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/tt.jpg' width="120">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                Applied Machine Learning Intern, Summer 2020
                <br> <a href="https://www.bytedance.com/en/">ByteDance Inc.</a>, Mountain View, USA
                <br> Host: <a href="https://www.linkedin.com/in/velicue/">Ming Chen</a>,
                <a href="https://scholar.google.com/citations?user=Y5uwWeAAAAAJ&hl=en">Youlong Cheng</a>
                <p></p>
                <p>Neural architecture search for large scale advertising models on TPU Pods.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/bcai.png' width="120">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                Research Intern, Summer 2019
                <br> <a href="https://www.bosch.us/our-company/innovation/">Bosch Research</a>, Sunnyvale, USA
                <br> Host: <a href="https://scholar.google.com/citations?user=9snl7bcAAAAJ&hl=en">Huan Song</a>,
                <a href="https://sites.google.com/site/liurenshomepage/">Liu Ren</a>
                <p></p>
                <p>Unsupervised domain adaptation with image and time-series data.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/ebay_logo.png' width="120">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                Research Intern, Summer 2017
                <br> <a href="https://tech.ebayinc.com/research/">eBay Research</a>, Aachen, Germany
                <br> Host: <a href="https://scholar.google.com/citations?user=EQhruhUAAAAJ&hl=en">Shahram Khadivi</a>,
                <a href="https://scholar.google.com/citations?user=hKCOyOkAAAAJ&hl=en">Evgeny Matusov</a>
                <p></p>
                <p>Adapt neural machine translation to e-commerce domains, published as <a href="https://arxiv.org/abs/1906.03129"> <font color="red"><strong>oral presentation</strong></font> </a> on IWSLT 2018. </p>
              </td>
            </tr>

          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <h2>Service</h2>
            </td>
          </tr>
          </table>
          <table width="100%" align="center" border="0" cellpadding="5"></tbody>
          <tr>
            <td style="padding:10px;width:25%;vertical-align:middle"><img src="images/ml_logo.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://sites.google.com/view/automl2021">PC member, AutoML Workshop, ICML 2021</a>
              <br>
              <br>
              <a href="https://sites.google.com/view/nas2021/organization?authuser=0">PC member, NAS Workshop, ICLR 2021</a>
              <br>
              <br>
              <a href="https://icml.cc/Conferences/2020/Reviewers">Reviewer, ICML 2020, 2021, 2022</a>
              <br>
              <br>
              <a href="https://neurips.cc/Conferences/2020/ProgramCommittee">Reviewer, NeurIPS 2020, 2021</a>
              <br>
              <br>
              <a href="https://iclr.cc/Conferences/2021/Reviewers">Reviewer, ICLR 2021, 2022</a>
              <br>
              <br>
              <a href="http://cvpr2021.thecvf.com/node/181">Reviewer, CVPR 2021, 2022</a>
              <br>
              <br>
              <a href="http://iccv2021.thecvf.com/node/39">Reviewer, ICCV 2021</a>
              <br>
              <br>
              <a href="https://eccv2022.ecva.net/">Reviewer, ECCV 2022</a>
              <br>
              <br>
              <a href="https://www.jmlr.org/tmlr/">Reviewer, TMLR 2022</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/kinect.png" width="160">
            </td>
            <td width="75%" valign="center">
              <a href="https://www.lfb.rwth-aachen.de/en/education/ip/">TA for Bachelor, Kinect Programming, Fall 2015</a>
            </td>
          </tr>
          </table>

          <!---
          <br>
          <br>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <h2>Award</h2>
            </td>
          </tr>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20"></tbody>
            <tr>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://icml.cc/Conferences/2020/Reviewers"> Top Reviewers, ICML 2020 </a>
                <br>
                <br> <a href="https://github.com/MSU-MLSys-Lab/MSUNet"> 4th Place of Google MicroNet Challenge, NeurIPS 2019 </a>
                <br>
                <br> <a href="https://www.jiqizhixin.com/articles/2019-10-31-5"> Best Paper Award Nominee, ICCV Neural Architects Workshop, 2019 </a>
                <br>
                <br> <a href="https://www.kaggle.com/c/data-science-game-2016-online-selection/leaderboard"> World Finalist, Kaggle Data Science Game, 2016 </a>
                <br>
                <br> Summer School Exchange Student, Tsinghua University, 2015 </a>
                <br>
                <br> Meritorious Winner, International Mathematical Contest In Modeling (MCM), 2014 </a>
                <br>
                <br> First Prize Scholarship, Xidian University, 2012-2014 </a>
              </td>
            </tr>
          --->

            <br>
            <br>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Talks</h2>
              </td>
            </tr>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20"></tbody>
              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="data/Dec3_UT_Austin_shenyan.pptx.pdf"> From Architecture Embeddings to Learning Curve Extrapolations, UT Austin, Dec 2021 </a>
                  <br>
                </td>
              </tr>

          </table>




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a style="font-size:small;" href="https://jonbarron.info">This guy makes a nice webpage.</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

